# 计算机组成原理

## 计算机结构

冯诺伊曼体系结构，也叫做存储程序计算机，存储程序其实包含了两个概念，可编程和可存储，如果计算机可编程不可存储，那么编写好的程序就不能存储起来下一次使用，如果计算机可存储不可编程，例如计算器只能进行加减乘除而做不了其他任何事，总之，不可编程和不可存储都大大降低了计算机的效率，这也就是存储程序计算机的由来

冯诺伊曼体系结构中，运算器(包括算数逻辑单元(ALU)和处理器寄存器)负责算数和逻辑运算，控制器(包括指令寄存器和程序计数器)负责控制程序流程，存储器(包括内存和硬盘等外存)负责存储数据和指令，输入和输出设备

现代所有计算机都是基于冯诺伊曼体系结构设计开发的，因此也就是计算机中任何一个部件都可以归到运算器，控制器，存储器，输入和输出设备中，而所有的程序都可以抽象为从输入设备读取输入信息，通过运算器和控制器执行存储在存储器中的程序，最后将结果输出输出设备中

![冯诺伊曼体系结构](./pics/Von_Neumann_architecture.jpeg)

图灵机，其基本思想就是用机器模拟人通过纸笔进行数学运算的过程，图灵机被认为是能够模拟所有人类可计算的计算过程，因此如果图灵机被实现那么就可以解决任何可计算的问题，也就是图灵完备(常说的某个编程语言是否图灵完备即是指该语言能否模拟出图灵机，图灵不完备的语言常见原因比如无限循环或递归受限(不支持`while(true)`)，这样也就是不能模拟无限长的纸带)

人通过纸笔进行数学计算分为两步，第一步在指纸上写上或擦除某个符号，第二步从纸上的一个位置移到另一个位置(在每个阶段人决定下一个动作依赖于人当前关注的符号和当前的思维状态，对应图灵机中的规则表)。图灵机模拟了这一过程，该机器有以下几个部分组成：
- 一个无限长的纸带，纸带被分为无数个连续的小格子，每个小格子上包含一个来自有限字母表的符号
- 一个读写头HEAD，其能够在纸带上左右移动并改变当前格子上的符号
- 一个状态寄存器，用于保存图灵机当前所处的状态，图灵机所有可能的状态数目是有限的
- 一套控制规则表，根据当前机器所处的状态以及当前读写头所指的格子上的符号来确定下一步的动作(修改当前符号/向左或向右移动读写头/修改状态寄存器)

冯诺伊曼体系结构侧重于硬件抽象，而图灵机侧重于计算抽象

## 衡量CPU性能

CPU的主频，比如2.8GHz指的就是在1秒内可以执行的简单指令数量为2.8G条，更准确的说这2.8GHz代表CPU中的时钟能够识别出来的最小的时间间隔，CPU中的时钟就是晶体振荡器(Oscillator Crystal)，晶振每“滴答”一下就是一个时钟周期

time命令可以统计该程序实际在CPU上所花的时间，time命令会返回三个值：
- real time：运行程序整个过程中消耗的时间，包括了CPU切换去执行比的程序或等待IO操作等
- user time：CPU在运行该程序，在用户态运行指令的时间
- sys time：CPU在运行该程序，在内核态运行指令的时间
所以，程序实际花费的CPU执行时间 = user time + sys time。注：在多核CPU中可能user time + sys time > real time，因为程序中指令可能被分配在多核上并行执行

程序的CPU执行时间 = CPU时钟周期数 * 时钟周期时间 = 指令数 * 每条指令的平均时钟周期数(Cycles Per Instruction，CPI) * 时钟周期时间
因此要解决性能问题就可以从三个方面入手：
- 指令数：代表执行该程序需要多少条指令，用哪些指令，这个很多时候都是交给编译器，编译器负责编译成最优的机器指令
- 每条指令的平均时钟周期数CPI：代表一条指令需要多少个CPU时钟周期，现代CPU通过流水线(pipline)技术让一条指令所需的CPU时钟周期尽可能少
- 时钟周期时间：就是CPU主频，这个取决于硬件

## 指令和运算

CPU指令可以分为五类：
- 算术类指令：加减乘除
- 数据传输类指令：变量赋值，向内存中写入数据
- 逻辑类指令：逻辑上的与或非
- 条件分支类指令：if/else/switch
- 无条件跳转指令：函数调用就是发起一个无条件跳转指令

CPU中有很多功能不同的寄存器：
- PC寄存器(Program Counter Register)：指令地址寄存器，用于存放下一条需要执行的计算机指令的内存地址(注：PC寄存器是个抽象的概念，IP指令寄存器和CS代码段寄存器是CPU中集体用来实现的寄存器)
- 指令寄存器(Instruction Register)：存放当前正在执行的指令
- 条件码寄存器(Status Register)：一个标记位(1/0)存放CPU进行算术运算和逻辑运算的结果，比如零标志(ZF)，进位标志(CF)，符号标志(SF)，溢出标志(OF)
- 除了上述这些特殊的寄存器外，还有很多用来存储数据和内存地址的寄存器，比如整数寄存器，浮点数寄存器，地址寄存器，还有些寄存器既能存放数据又能存放地址，称之为通用寄存器

CPU从PC寄存器中取出地址，找到地址内存中的指令，交给指令寄存器中执行，然后将PC寄存器中指令地址递增，重复操作，如果遇到跳转指令，就会修改PC寄存器中的地址从而下一条指令地址不再是连续的而是跳转到指定位置

`if (i == 0) { print("0"); } else { print("1"); }`其中`a == 0`被编译成了cmp和jne两条指令，首先通过cmp对i变量和值0进行比较，将结果存放到零标志条件码寄存器中，如果是true就置为1反之为0，接着jne(jump if not equal)指令查看零标志条件码寄存器值，如果为0(代表上一步比较结果为false)就进行跳转到后面跟着的操作数位置(即PC寄存器不再是递增而是设置为操作数地址)，操作数的位置在汇编中就代表这汇编文件的行号，在CPU运行是会代替为具体的内存地址。通过判断加跳转的操作就能实现if/else的逻辑

```txt
    if (i == 0) 
3b:                                           cmp [rbp-0x4],0x0
3f:                                           jne 4a
    {
        print("0");
48:                                           jmp 51
    } 
    else 
    {
4a:
        print("1");
51:
    }
```

`for (int i = 0; i < 10; i++) { print("hello); }`被编译成汇编后，当进入for代码段后就会进行一个jmp指令跳转，跳转到for代码段的最后，for代码段的最后汇编会添加上cmp和jle指令，首先cmp指令负责进行`i < 10`的判断，接着jle会判断上一步cmp的结果，如果说明还需要进行循环即跳转到jle指令后的行号处，该行号即代表着for循环中真正的逻辑代码，否则就继续向下执行即跳出了循环。相较于if/else，for循环中的跳转会跳转到所在行号之前的行号，从而达到循环的操作，而if/else只需要向后面的行号进行跳转即可

```txt
    for (int i = 0; i < 10;i ++) 
    {       
12:                                            jmp 1e
17:     
        print("hello");
1e:                                            cmp [rbp-0x8],0x10
22:                                            jle 17
    }
```

`add(a, b)`main函数中调用add函数被编译成汇编后，call指令会把当前PC寄存器中下一条指令的地址压栈(调用push eip)，从而当add函数调用完成后能够恢复main函数中要继续执行的指令地址，接着跳转到call指令后跟着的行号，即add函数处，在执行add函数中执行具体逻辑前，首先将rbp压栈(push rbp)，然后将rsp中的地址赋给rbp(mov rbp,rsp)(rbp和rsp本来指向的是main函数的栈帧，进入add函数就固然需要指向add函数的栈帧，因为add函数还没开始执行逻辑代码，因此此时rbp和rsp是指向同一个内存地址的，因为此时栈帧内还没数据)，接着执行add函数的逻辑，在执行完后退出add函数前会通过pop rbp将add函数的栈帧弹出系统栈，接着ret指令会自动弹栈(pop eip)，即将main函数需要恢复执行的指令地址赋给PC寄存器完成整个add函数的调用并继续执行main函数

为什么需要用到栈？对于main函数调用add函数来说，其实最重要的是add函数执行完后如何知道从main函数中的哪开始继续执行，可以使用寄存器来保存main函数执行到的位置从而让add函数执行完后明白从哪继续执行，但是函数调用是会嵌套的，即add函数中可能还会调用别的函数，而寄存器又是有限的，那么就要借助到栈这种数据结构，每个函数所占的栈中的内存空间称为栈帧(Stack Frame)，此外函数间大量的参数传递和复杂的数据结构也是通过压栈的方式进行传递的，总之，栈其实就是解决了寄存器个数有限从而无法实现复杂功能的问题

内存中栈的布局是固定的，栈的底在高地址处，而顶则是在低地址处，所以一次次的压栈，栈顶的内存地址从高地址向低地址移动，可以说内存中的栈是个倒放的栈容器，所以说的压栈操作其实在真是内存中更像是在栈顶附加新的数据

push指令：将一个寄存器中的数据压栈
pop指令：出栈用一个寄存器接受数据

rsp寄存器：栈指针寄存器，其中的指针永远指向系统栈最顶端的一个栈帧的栈顶
rbp寄存器：基址指针寄存器，其中的指针永远指向系统栈最顶端的一个栈帧的栈底

```txt
    0000000000000000 <add>:
    int static add() 
    {
0:                                             push rbp
1:                                             mov rbp,rsp
        return a + b;
12:                                            pop rbp
13:                                            ret
    }
    0000000000000014 <main>:
    int main() 
    {
14:                                            push rbp
15:                                            mov rbp,rsp
        int a = 10;
        int b = 20;
34:                                            call 0 <add>    
        int c = add(a, b);
42:                                            ret
    }
```

因为函数调用依赖于栈，而内存中的栈的大小又是有限的，那么当函数调用层次过深时(比如无限递归)就会导致栈溢出(stack overflow)

通过函数内联优化(Inline)：在编译时直接将函数具体代码插入到调用的位置来替换对应的函数调用，比如调用add函数直接修改为a + b，从而使得CPU需要执行的指令数变少了，也无需根据地址跳转到调用的函数处，压栈和出栈也不再需要，但是如果这个函数是个通用函数，被多处调用，那么内联就会导致程序大小膨胀
