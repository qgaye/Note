# 计算机网络

## IP

通过`ip addr`或`ifconfig`查看ip地址

![IP地址范围](./pics/ip_scope.jpg)

IPV4只有32位不够用，因此有了现在的IPV6，有128位

分类不合理，本身紧张还被分成了5类，C类的私有ip范围只有254个不够用，而B类的私有ip范围有6w个，太多了

因为分类不合理，于是出现了CIDR(无类型域间选路)来设计地址，将IP地址一分为二，前者网络号，后者主机号

于是又有了广播地址和子网掩码的概念

IP分为共有IP和私有IP

192.168.0.x是最常用的私有IP地址，192.169.0是网络号，192.168.0.1通常是私有网络的出口ip，192.168.0.255是广播地址

MAC地址和IP地址：

一个网络包要从一个地方传到另一个地方，除了要有确定的地址，还需要有定位功能

举例来说MAC地址就像你的身份证号，身份证号是唯一的但是别人无法通过身份证号直接找到你，此时别人就可以根据ip地址来定位到你的位置，比如你在互金，别人就知道先坐地铁12号线，再坐地铁4号线(这个过程就相当于路由器路由，用的是IP地址)，当到了互金后，大喊你的身份证号码就能找到你了(这个过程相当于交换机转发，用的是MAC地址)

总结：MAC地址通信范围比较小，只能在一个子网里跨子网就必须用到IP地址

## DHCP

IP地址可以随意配置，但用户自行配置往往会出现问题。比如你想接入的机器都是192.168.1.x，但自己配置了个16.158.23.6的ip地址，即使你想ping的地址192.168.1.6就在你旁边，但是Linux系统可不会如你所愿直接发给旁边的192.168.1.6

在网络上的包必须是完整的，不能有上层没下层，意思就是有ip没用，还得有MAC地址才能把包发出去，因此Linux首先会去获取目标地址的MAC地址，但是当目标地址和本机地址是同一个网段，才会发送ARP请求来获取目标地址的MAC地址，很显然现在目的ip和本机ip不在一个网段，此时Linux认为这是一个跨网段调用，就会直接发给网关。如果配置了网关Linux就回去获取网关的MAC地址，然后将包发给网关，网关那能不能成功发送到192.168.1.6就得看网关上有没有做过配置了。如果没有配置网关，那么包压根发不出去。如果想把网关配成192.168.1.6，对不起，Linux不会让你配置成功的，因为网关至少和一个网卡在同一网段中的

DHCP(动态主机配置协议)就是帮助新接入的机器自动配置CIDR、子网掩码、广播地址和网关地址这些信息的

1. 新接入的机器会发送广播包(UDP封装的BOOTP)，其中带上自己的MAC地址请求个ip地址，这个称为DHCP Discover
2. 网络中的DHCP Server会感知到新接入的机器，此时会从地址池中分配一个未使用的ip地址给它给，并将子网掩码、网关和IP地址租用期等信息广播发送给新机器，这个称为DHCP Offer
3. 新机器此时可能会接收到多个DHCP Offer，一般会选取第一个到达的，并将MAC地址，接受的ip地址，提供该地址的DHCP服务器地址等信息通过广播的方式发送，主要为了告诉其他的DHCP服务器可以撤销提供给他的ip，这个称为DHCP Request
4. DHCP接收到新机器的DHCP Request后，会广播给新机器DHCP ACK包，表明已接受新机器的选择，并让网络中其他机器也感知到

DHCP还可以通过PXE(预启动执行环境)可以自动为新来的机器配置操作系统

## 交换机和集线器

当只有两台机器的时候可以通过网线直连，但当机器数大于两台时，就需要集线器或者交换机

集线器(Hub)是完全工作在物理层的，它将收到的所有字节全部复制到其他端口上，即广播模式

多路访问用于控制谁先发，谁后发，来防止混乱，主要有以下三种方式
- 信道划分：分成多个道，你走你的，我走我的
- 轮流协议：先你发，再我发，轮着来
- 随机接入协议：都直接发出去，遇到堵塞再退回来等空闲再发，以太网用的就是这个协议

交换机(Switch)是具有MAC地址记忆能力的，当第一次请求MAC地址的端口不知道时，它会先广播给所有端口，接着它会记录MAC地址和端口的映射关系，并带上一个过期时间，这个称作转发表

集线器是共享带宽，而交换机是独占带宽

当多台交换机连接起来时会存在环路问题，简单来说就是询问机器2的MAC地址的ARP请求到达交换机A的时，交换机A不清楚于是就广播给LAN2，接着交换机B纠结收到了交换机A在LAN2中广播，于是交换机B发现自己也不清楚，于是又转发给LAN1，接着交换机A又会接收到来自交换机B的广播，于是开始了周而复始的循环

![环路问题](./pics/network_switch_cycle.jpg)

计算机网络中使用STP协议来解决环路问题，其原理就是打破环构成的图，通过节点间的比较，选择一个为父一个为子来打破环，构成最小生成树

当机器和交换机越来越多，网络也越来越大，此时广播的性能毫无疑问会急剧下降，并且隐私性也无法保障，此时可以通过虚拟隔离(VLAN，虚拟局域网)来将机器隔离在不同的局域网中

此时需要将数据链路层的数据包的头上加一个TAG，里面有一个VLAN ID，这个VLAN ID共12位，因此最多只能划分4096个VLAN

如果交换机支持VLAN，那么就可以配置每个端口所属的VLAN，当数据包来时，交换机会识别出VLAN ID，并转发给相同VLAN的端口，即只有相同VLAN的包才会互相转发

对于支持VLAN的交换机有一种Trunk的接口，它可以转发任何VLAN的包，因此交换机之间可以通过这个接口连接

## ICMP

ICMP(Internet Control Message Protocol)：互联网控制报文协议，ICMP报文是封装在IP包里的

![ICMP](./pics/network_icmp.jpg)

ICMP有很多不同类型，不同类型使用不同的代码，最常用的类型是主动请求为8，主动请求的应答为0

查询报文类型：

ping就是查询报文，ping的主动请求称为ICMP ECHO REQUEST，主动请求的回复称为ICMP ECHO REPLY

比起原生的ICMP其中多了两个字段，一个是标识符，另一个是序号

ping命令执行时会首先构建一个ICMP请求包，类型字段为8，序号(顺序号)在每发出一个请求包后加1，并会插入发送时间用于计算往返时间RTT，接着交给网络层和数据链路层构建数据包，最后发出数据包，如果没有接收到ICMP应答包，就说明目标地址不可达，如果接收到就表示可达

差错报文类型：

差错报文主要就是报告出现问题的原因，不同类型字段代表不同的错误状态，比如终点不可达为3，源抑制为4，超时为11，重定向为5

traceroute就是故意制造一些错误的场景，来获取差错报文以分析信息，比如traceroute会发送一份UDP数据包给目标地址，但目标端口设成超出范围的值，当目标主机生成返回一个端口不可达的ICMP差错报文，你就知道了数据包是送达的，如果差错报文是超时，那就说明数据包未达到目标地址(主要原因是UDP是无连接的，即收不到回复的)

## 网关

当Linux发现目标ip地址和本机ip地址不在同一网段时，就会发送给网关，网关往往是个路由器，但不一定是路由器，其本质是个处在网络层的转发设备，它会解给别的设备析MAC头和IP头，并决定转发 

静态路由：

静态路由就是在路由器上自行配置一条条转发规则，比如目标网段192.169.3.x转发到3号口，其中具体分为转发网关和NAT网关

转发网关：不改变ip地址的网关，路由器只会在转发时修改目标MAC地址

NAT网关：改变ip地址的网关，目标地址不在同一局域网中但网段却相同，因此就要暴露一个公网ip供使用，路由器在转发公网ip到内网ip时不但会修改目标MAC地址，还会修改目标ip

NAT(Network Address Translation)：网络地址转换

除了根据目标ip配置路由外，还可以通过参数来配置路由，比如让指定源ip走指定网口转发

动态路由：

动态路由的核心就是如何在两个路由间找到最短路径，图中有两种方法Bellman-Ford算法和Dijkstra算法

距离矢量路由算法：

距离矢量路由算法是基于Bellman-Ford算法的，基本思想就是每个路由器中保存着一个路由表，其包含多行，每行包含两部分信息，一个是目标路由器，另一个就是到目标路由器的距离

每个路由器都是知道自己和邻居间的距离的，每过几秒，路由器就会将自己知道的目标路由器和距离告诉邻居，邻居路由器只需要将距离+1就能更新自己的路由表了

其存在两个问题：
1. 坏消息传的慢：比如A路由器记录到X路由器距离1，邻居B路由器记录到X路由器距离2，此时X路由器挂了，A路由器连不上X路由器了，但他发现它邻居B路由器到X路由器距离是2，因此他就更新自己到X路由器距离为3，接着C路由器也连不上X路由器了，但他发现邻居A路由器到X路由器距离为3，于是也更新了自己距离，往复循环，直到他们到X路由器的距离更新到了阈值，他们才正真明白X路由器原来挂了
2. 每次发送时都要发送自己整个路由表：当网络大了，这个路由表就会非常大，传输效率就会很低，因此小型网络(小于15跳)使用的路由协议RIP才会使用该算法

链路状态路由算法：

链路状态路由算法是基于基于Dijkstra算法的，基本思想就是路由器启动时会向say hello，得到邻居回复后就能计算出之间的距离了，接着将自己和邻居间的链路状态广播给整个网络，这样整个网络中的路由器都知道了这个关系，每个路由器都能够在本地构建一个完整的图，接着在这个图上使用Dijkstra算法找出两点间的最短路径

其只需要广播两两之间的关系而不用广播整个路由表，因此数据包很小，其次一旦有路由器挂了，邻居路由器就会广播这个消息，从而使得坏消息也能及时更新

动态路由协议：

OSPF：

OSPF(Open Shortest Path First)：开放式最短路径优先，其基于链路状态路由协议，由于主要用于数据中心中的协议，因此被称为IGP(Interior Gateway Protocol，内部网关协议)

OSPF能够发现图中存在的多个最短的路径，并在这些路径中进行负载均衡

BGP：

BGP(Border Gateway Protocol)：外网路由协议，其基于增强版的路径矢量路由协议，在外网中虽然存在更短的路径，但是这条路径不一定允许你使用

因此会将网络分为一个个自治系统AS(Autonomous System)
- Stub AS：对外只有一个连接，这类AS不会传输其他AS的包，比如个人或者小公司的网络
- Multihomed AS：可能有多个连接连到其他的AS，但是大多拒绝帮其他的AS传输包，比如一些大公司的网络
- Transit AS：有多个连接连到其他的AS，并且可以帮助其他的AS传输包，比如主干网

BGP分为两类，eBGP和iBGP，边界路由器(AS间相连的)使用eBGP广播路由，AS内部使用iBGP找到最短路径的边界路由器来到达外网

在BGP中相较于距离矢量路由算法除了下一跳距离外，还会带上AS路径，因此A是知道B是通过自己知道的X，因此当A连不上X后，不会再通过B来更新，解决坏消息传递慢的问题，其次整个网络中将AS看作整体，而不再关注AS中一个个具体的路由器，因此即使共享整个表问题也不大

## TCP/UDP

数据包是UDP还是TCP通过IP头中的8位协议判断

### UDP

UDP(User Datagram Protocol)：用户数据包协议，UDP是无连接的，不能保证可靠的交付数据，没有拥塞控制

UDP将应用层的数据直接加上UDP的首部信息发送出去，即面向报文传输的协议，UDP首部开销小，只有8个字节

![udp首部](./pics/udp_head.png)

因为UDP首部开销小，无连接等特性，其适用于三种场景：
- 对丢包不敏感的应用：DHCP
- 无需建立连接的广播应用：DHCP
- 需要处理速度快，时延低，容忍少量丢包，即使网络拥塞也要尽快送达：流媒体协议，实时游戏

### TCP

TCP(Transmission Control Protocol)：传输控制协，TCP提供一种面向连接的、可靠的字节流服务

所谓面向字节流就是指TCP会将用户的数据块进行合并或分拆，然后进行传输(IP包本身不是流，而是一个个数据包)

![tcp首部](./pics/tcp_head.png)

![tcp标记位](./pics/tcp_remark.png)

重要的是SYN置1表示该请求在请求连接，ACK置1表示此时请求中确认号是有效的，FIN置1表示该请求在释放连接

TCP首部20个字节，带上可选的最多60个字节

TCP的可靠传输是基于滑动窗口实现的，对于发送端来说存在滑动窗口分为四段：发送且确认的，发送但未确认的，未发送但可发送的(Advertised Window)和未发送且不可发送的

TCP采用累计确认的方式，当发送端接收到ACK表示这个ACK序号前的所有报文都接收到了，相对于单停等协议来说减少了ACK的传输并且可以一次性发送连续的多个报文

确认和重传机制：每个数据包发送后都必须收到个ACK包，当数据包发送后会启动个定时器，当超过一定时间(就是超时时间，通过采样RTT平均时间和波动范围确定，称为自适应重传算法)，就会重传，且每次超时重传后都会将超时时间设为原先的两倍，因为屡次超时就说明网络拥塞，不宜频繁发送

超时触发重传存在超时周期过长问题，因此快重传机制(也是拥塞控制的机制)，一旦发现一个失序报文，就立刻发送三个冗余的ACK(序号为失序的前一个)，发送端接收到后就不等超时立刻重传

### TCP是如何数据可靠传输

- 校验和
- 确认应答 + 序列号 
- 超时重传 
- 流量控制 
- 拥塞控制

### TCP流量控制

流量控制的作用是让发送方感知到我这能接受的能力，就是不要发送的太快

流量控制是通过滑动窗口实现的，TCP首部里有窗口字段(Advertised Window)，可以用来告诉发送方我这里现在可容纳的窗口大小，当接收方告诉发送方窗口大小为0时，此时发送方会启用一个坚持定时器，来定时探测接收方的窗口大小，这是为了解决接收方传递可用的窗口大小时丢失造成死锁的情况

### TCP拥塞控制

流量控制考虑的是接收方，拥塞控制考虑的是整个网络，拥塞控制主要为了避免两种现象：包丢失和超时重传

慢启动算法：

拥塞窗口由小到大 1，2，4，8指数级扩大，当到达慢启动阈值时，启用拥塞避免算法

拥塞避免算法：

只要网络不拥塞就试探调大拥塞窗口(每次 + 1)，旦发现拥塞(即超时了)，那么就将慢启动阈值设为原来的一半，从1开始重新慢启动算法

快重传：

快重传要求接收方一旦发现一个失序报文，就立刻发送三个冗余的ACK(序号为失序的前一个)，发送端接收到后就不等超时立刻重传认，随后进入快恢复算法

快恢复：

在接收到3个以上的重复ACK后将慢启动阈值设为原来一半，并从一半的位置开始执行拥塞避免算法

BBR(Bottleneck Bandwidth and Round-trip propagation time)：

TCP拥塞控制的目标是最大化利用网络上链路的带宽，一条网络链路就像一条水管，水管中水越满就说明带宽用得越充分
水管内的水的数量 = 水管的容积 = 水管粗细 x 水管长度
网络内尚未被确认收到的数据包数量 = 网络链路上能容纳的数据包数量 = 链路带宽 x 往返延迟

上述的都是基于丢包的拥塞避免算法(不断增加发送窗口，直到发现开始丢包)，但是在实际中，丢包并不一定代表通道拥塞了，公网上存在着一定比例的丢包率，而上述的拥塞避免算法一旦发现丢包，就认定网络拥塞了，这毫无疑问是错误的选择。其次网络中会有一些buffer，上述的拥塞避免算法是通过灌水进水管的方式测试网络可接受的最大数据包量(不断增加发送窗口，直到发现开始丢包)，这毫无疑问会将buffer空间也计算进去，虽然看似网络中能接受的数据包量变多了，但buffer中的包是必须等待着被传输的，因此时延增长，此外如果连接较多时，可能会导致缓冲区被填满而丢包，这个问题被称为bufferbloat(缓冲区膨胀)

综上所述，BBR致力于解决两个问题：
1. 在有一定丢包率的网络链路上充分利用带宽
2. 降低网络链路上的buffer占用率，从而降低延迟

BRR解决策略：
1. 既然不容易区分拥塞丢包和错误丢包，BBR就干脆不考虑丢包
2. 既然灌满水管的方式容易造成缓冲区膨胀，BBR就分别估计带宽和延时，而不是直接估计水管的容积

但是带宽和延时是无法同时测准的，因为带宽最大时缓冲区会被占用，从而延时较大，当延时最小时，就要求缓冲区为空，那么带宽就较小，因此只能交替测量来得到带宽的最大值和延时的最小值

BBR流程：
1. 慢启动：指数级增加发包速率，直到将整个网络填满，包括缓冲区(而上述算法在有一个丢包时就会进行拥塞控制)，当有效带宽不再变化时就说明塞满了，于是进入拥塞避免
2. 排空阶段：指数级降低发包速率，直到延时不再降低时，就说明整个网络中buffer被排空了

慢启动的最后带宽用作计算，因为此时带宽值最大，慢启动的最开始延时用作计算，因为此时延时最小

### TCP三次握手：

![三次握手](./pics/tcp_3.png)

为什么需要第三次握手，事实上第二次握手的时候客户端已经处在连接建立的状态(第三次握手SYN不等于1了)，但是存在一种客户端第一次建立连接请求在网络中过了很久才到达服务端，客户端以为超时重传了，而重传的很快服务端就回应了，而后客户端第一次的请求到了服务端，服务端不知道这个请求已经被重传过了，因此也回应了，如果此时是两次握手建立连接，那么两个连接就会被建立，而其中一个是平白无故占用服务端资源的，因此第三次握手就是来解决这种情况

为什么不是四次握手，毫无疑问第三次客户端向服务端挥手后也是没法感知到服务端有没有收到的，因此第四次挥手是可以的，但是客户端怎么保证第四次挥手服务端一定收到了呢，那是不是就要第五次挥手了，从而就变成无止境的相互挥手了(究其原因是因为客户端和服务端之间永远没有办法确切感知到对方的存在)，因此第四次挥手是可以的，但四万次挥手都没法保证连接一定可靠，只要消息有来有回，就认定是成功建立连接了

### TCP四次挥手：

![四次挥手](./pics/tcp_4.png)

在客户端进行最后一次挥手后会启动一个等待定时器，在等待2MSL(MSL为最长报文段寿命，通常为2分钟)，其作用是因为最后一次挥手后服务端是没有确认回复的，因此客户端需要确认服务器接收到了客户端的挥手，服务端在发起断开连接后在2MSL中如果没有收到确认，会重传，此时客户端处在等待2MSL中，因此就能回答。此外等待2MSL还能保证整个连接中的报文段都过期了，这样上一个连接中的迷失的报文段就不会影响到后一次的连接了

注：MSL(Maximum Segment Lifetime)和TTL(Time to Live)都和报文生存有关，只是前者是时间维度而后者是经过路由跳数，不是时间单位，而RTT(Round-Trip Time)是往返时延

出现大量time_wait原因：即你是主动释放连接的一方，也可以设置快速回收time_wait的连接或允许将time_wait的连接应用于新的TCP连接

出现大量close_wait原因：代码中建立的连接没去close

## Socket

`{源IP, 源Port, 目标IP, 目标Port, 协议号}`来标识不同的Socket，五元组中任意一个不同就不是同一个Socket

Socket在Linux中是以文件的形式存在的，还存在文件描述符，写和读都是通过文件描述符的

基于TCP的Socket编程：

通过bind函数指定ip和端口，ip用于指定监听机器上的网卡，端口用于让内核能将数据包发给应用程序
调用listen函数开始监听，此时客户端就可以发起连接了，叫作监听Socket
客户端通过connect函数发起连接，内核会分配一个临时端口给它建立连接，这是由监听Socket完成的
服务端通过accept函数会获得一个新的Socket连接，叫作已连接Socket，用于read/write

基于UDP的Socket编程：

通过bind函数指定ip和端口即可，无需listen和connect，因为UDP是无状态的，无需每对连接建立个新的Socket，每次通过sendto和recvfrom即可

处理大量Socket：

// TODO: 
1. 多进程/多线程
2. IO多路复用 select
3. IO多路复用 epoll

因为TCP是要创建连接的，因此同一个端口只能由一个TCP服务监听，但UDP是无需连接的，因此同一个端口可以由多个UDP服务监听

同一个端口上可以同时被TCP和UDP监听，因为TCP/UDP底层都是IP层，只是通过标识符区分了TCP/UDP，因此监听同一个端口号不冲突

## HTTP

HTTP是个应用层的协议，其特点是无连接，无状态的

无连接：HTTP协议限制每次连接只处理一个请求，当客户端收到应答后就立即断开连接，从而将资源释放来服务其他客户端，但到了后期网页越来越复杂，每次请求都建立个TCP连接就很低效，于是在HTTP1.1中使用Connection:keep-alive方式来复用TCP连接 (总结就是早期的HTTP是无连接的，但在HTTP1.1后是可以保持连接的)

无状态：HTTP对请求没有记忆功能，即每个请求都是独立的，因此就需要通过cookie和session来维护状态

HTTP请求报文分为三大部分：请求行(请求方法，URI，HTTP版本)，首部字段，报文主体

HTTP返回报文也分为三大部分：状态行(状态码，HTTP版本)，首部字段，报文主体

首部字段：Accept-Charset表示客户端可以接受的字符集，Content-Type表示报文主体格式，Cache-Control表示采用的缓存策略

### HTTP缓存：

服务器可以通过设置Cache-Control来指示代理服务器或浏览器采用何种缓存策略，并且可以设置缓存时间来表示在缓存时间内浏览器可直接使用缓存

但是如果资源是会变换的，那么Cache-Control会使得用户页面无法即使刷新，因此服务器在返回资源时会带上ETAG来表示该资源版本，然后浏览器再次请求时会带上If-None-Match字段来询问服务器该资源是否继续可用，如果服务器发现该版本资源依旧是最新的资源，就返回304状态码

Last-Modified与ETAG相似，只是不再表示版本而是修改时间，对应的请求字段If-Modified-Since，只要服务器发现在这个时间后该资源没被更新过，就返回304状态码

只有从新标签页打开或超链接打开的情况下浏览器会直接根据Cache-Control缓存头字段来判断是否直接使用磁盘缓存

如果是正常的刷新或在标签栏重新回车访问，此时浏览器会将Cache-Control设为max-age=0即失效，然后带上If-None-Match或If-Modified-Since访问服务器

如果是强制刷新，浏览器不会使用任何缓存且在访问服务器时也不带任何条件字段

### HTTP版本

HTTP1.1:

- 默认使用Connection: keep-alive，使得TCP连接建立后可以被复用，长连接的优点：
  - 减少TCP请求次数，减少CPU和内存消耗，和减少请求响应时间
  - 允许http pipelining的请求响应模式，即客户端可以一次性发出多个请求，而不必等到一个请求响应完成后再发下一个请求
- 可以在头部传一个range，请求部分内容，实现断点续传

HTTP1.1中支持了长连接，因此即支持了管道网络(pipeline)，即允许客户端同时发出多个请求，但是服务器还是按照顺序依次返回，因此如果前面的请求响应很慢就会导致后面的请求被阻塞无法返回，即队首阻塞问题

HTTP2.0:

HTTP1.1在应用层以纯文本形式进行通信，且每次通信都要带上完整的HTTP头
- 对HTTP头进行压缩，将每次携带的kv在两端建立个索引表，对相同的头只需要发送索引表中索引即可
- 将一个TCP连接切分为多个流，每个流都有自己的ID，流其实就是个虚拟的通道
- 将传输的信息分割为帧，并采用二进制进行编码，二进制编码使得计算机无需对报文中比如换行符进行解析
- 以上两种特质使得在HTTP2.0中可以将多个请求分到不同的流中，然后拆分成帧以二进制形式乱序发送(乱序是指不同ID的流是乱序的，但同一个ID的流上的数据包还是顺序发送接收的)

HTTP2.0解决了1.1中队首阻塞问题，也无需使用HTTP1.1中pipline机制创建多条TCP(Chrome中默认同时创建6条，6条是因为浏览器对同一域名下的请求连接有条数限制)来实现并行请求(因为HTTP2.0中流的概念即达到了同时开多条TCP连接的作用)，减少了TCP连接数从而降低了对服务器性能的影响

![http1.1和http2.0区别](./pics/http1.1:2.0.jpg)

HTTP3.0:

HTTP2.0中虽然通过流的方式增加了并发性，但是HTTP2.0本身还是基于TCP协议的，所有所有数据包必须顺序的被接受，因此流的并行并不是真正意义上的并行，存在stream1的帧丢失后，需要重传导致阻塞了stream2的发送问题

HTTP3.0中将TCP切换到了UDP，这就是谷歌的QUIC

自定义连接机制：

TCP由源ip，源端口，目标ip，目标端口四个元素来确定，一旦一个元素发生变化，比如网络不稳定时，就需要断开重连，进行三次握手

QUIC在自己的逻辑中使用64位随机数作为ID来标示来维护连接，因为UDP是无状态的，因此即使ip和端口发生变化，只要ID不变就无需重新建立连接

自定义重传机制：

TCP中数据包通过自适应重传算法，采样往返时间RTT来调整超时时间以完成超时重传，但是TCP中重传的SYN和原先的SYN是相同的，那么收到的ACK是无法知晓是重传的ACK还是之前正常的ACK，既而无法准确计算采样往返时间RTT来设置超时时间

QUIC中也使用了序号的机制，但是这个序号是不断递增的，即任何一个序号发送后就需要+1，从而就能正确感知到是重传的ACK还是正常发送的ACK了，因为重传的序号会+1，因此需要个offset来表示发送的数据在整个数据流中的偏移量，从而保证客户端能正确舍弃重复的数据包

无阻塞的多路复用：

同HTTP2.0中一样，一条QUIC上也可以创建多个流来并行发送不同的HTTP请求，并且由于UDP是无连接的，因此流和流之间是没有依赖关系的，从而即使stream1流上的包丢失，需要重传，也不会阻塞接受stream2包的发送

自定义流量控制：

QUIC和TCP相同，也是通过窗口大小来告诉对端自己能接受的字节数，但TCP的累计确认的机制导致一旦一个ACK未收到，就要重传所有未确认的包(因为TCP是串行发送的，所以一个一个ACK会阻塞发送且耗时)，浪费带宽

QUIC的ACK则是基于offset的，每个offset的ACK进来都即表示这段已经收到了，因此重传时只需要重传没能收到ACK的即可，并且滑动窗口的起始位置是从当前收到ACK的最大offset开始，此时窗口范围才是真正表示流中能容纳的最大容量(TCP的起始位置是未收到ACK的序号，因此很可能窗口中大量需要已经被客户端收到了，而只是服务端没有收到ACK而已，容量不够准确)

### Cookie/Session

HTTP本身是无状态的，因此Cookie和Session是用来保存状态(比如是否登陆，用户自定义的设置等)

- Cookie保存在浏览器中，容易被获取，Session保存在服务器，相对安全
- Cookie可以设置保留时间，而Session在服务器处超时或重启后失效，如果浏览器不共享进程内存cookie，那么是会存在登陆后换个窗口又要重新登陆
- Cookie保存数据不得超过4K，而Session没有限制

设置HttpOnly=true来使得Cookie不能改够被js获取到，只能够通过AJAX传递

当使用Session时也依赖于Cookie，当用户第一次请求服务器时，服务器会创建对应的Session，并生成SessionId返回给浏览器，而浏览器会将这个SessionID记入Cookie中，在下一次访问中浏览器会带上这个域名下的Cookie，即对应的SessionID，服务器再通过SessionID找到对应的Session，从而达到保存状态的作用

如果浏览器端禁用了Cookie，那么可以通过重写URL，如以`?sid=SessionID`的形式将SessionID拼接到URL中，或者改用Token/JWT

分布式Session解决方案：
- Nginx ip_hash 策略：通过Nginx来保证相同IP一定访问到相同的服务器
- Session复制：每个服务器上Session增删改后，会把这个Session序列化后发送给所有其他服务器上
- 共享Session：服务器无状态，将Session统一使用缓存中间件管理

### JWT

通过session模式的用户认证存在扩展性问题，即当服务是集群时，就要求session在服务集群中共享，从而保证每台服务器都能通过session id找到对应的session，而session同步就比较复杂，并且有些情况下集群可能是多个不同服务，无法直接同步session，还得持久化层面去做同步

而JWT(JSON Web Tokens)则是目前最流行的跨域认证解决方案

JWT数据结构(`Header.Payload.Signature`)：
- Header(头部)：alg表示签名算法，typ表示token类型，jwt就是jwt
- Payload(负载)：iss表示签发人，exp表示过期时间，nbf表示生效时间，iat表示签发时间
- Signature(签名)：通过密钥(只有服务器知道，不能泄露给用户)，通过Header中指定的算法将Header和Payload计算得出签名
Header，Payload，Signature都是通过Base64URL算法进行转化，Base64URL相较于Base64对URL中敏感的符号(`=+/`)进行替换

客户端在与服务端通信时都必须带上JWT，可以将它放在cookie里自动发送，但最好显式的放在HTTP的Header中`Authorization: Bearer <token>`

JWT特点：
- JWT除了可以用作认证外，还可以用于交换信息，降低服务器查询数据库次数
- JWT本身不加密，如果需要交换密码信息，则需要对JWT进行额外加密
- JWT不同于session，服务器会保存session状态，因此一旦JWT签发后，除非JWT到了过期时间，否则无法在过程中废除该JWT(如果要求废除，需要自行建立一个JWT过期库，将废除的JWT存入其中，每个JWT都和这个库中做比较)
- JWT被获取后，任何客户端都可以通过该JWT完成认证功能，因此为了保证JWT不被盗用，使用HTTPS代替HTTP

### HTTP状态码

- 200 服务器成功处理了请求
- 204 服务器成功处理请求，但没有返回任何内容(CROS和RESTful的create里用到)
- 206 服务器处理了部分GET请求(HTTP1.1断点续传)

- 301 资源永久移动
- 302 资源临时移动
- 303 POST请求(非幂等)在重定向后会变为GET请求对重定向地址发起请求(规范上说明POST请求返回302需要浏览器弹窗让用户选择是否重定向，而浏览器却都直接以GET方法请求重定向地址，因此HTTP1.1中直接新增了这个状态码)
- 304 客户端缓存的资源继续可用

- 400 错误请求，请求的语法有问题
- 401 未授权，该请求要求身份验证
- 403 禁止，服务器拒绝了请求
- 404 资源未找到

- 500 服务器内部错误，无法完成请求
- 502 网关错误，服务器作为网关或代理，从上游服务器收到无效响应，比如通过Nginx发现后端服务没启动
- 503 服务器不可用，可能处于停机或维护状态，通常是暂时的
- 504 网关超时，比如Nginx迟迟收不到服务器的回答

### HTTP方法

- GET 幂等 获取数据
- POST 非幂等 创建数据
- PUT 幂等 更新数据
- DELETE 幂等 删除数据
- PATCH 非幂等 更新一部分数据，不存在时会创建

GET和POST方法没有实质区别，只是报文格式不同

- GET：用于获取数据，是无副作用的，具有幂等性，且可缓存
- POST：用于修改数据，有副作用，非幂等，不可缓存

GET使用URL/Cookie传参，而POST将数据放在Body里：这是HTTP协议的约定，事实上GET也可以设置Body

GET方式提交的数据有长度限制，而POST的数据则可以非常大：HTTP协议明确对HTTP头和Body不限制大小，而大小限制往往是服务器为了性能设定的

POST比GET安全，因为数据在地址栏上不可见，但究其实质都是不安全的，因为HTTP本身都是明文传输的

POST会产生两个TCP数据包？关于会产生两个还是一个TCP数据包事实上是由发送方自己实现的，如Chrome/curl等，HTTP协议中没有做限定。有些客户端在POST请求时会先将header带上`Expect: 100-continue`发出，在收到服务器100的响应码后再将发送data

当客户端有个HTTP实体部分要发送给服务器但又不清楚服务器是否接受这个实体，于是就通过`Expect: 100-continue`方式在HTTP实体发送前先发一个请求 进行确认，如果服务端接受这个实体，就会返回100的状态码

### URI/URL

URI：统一资源标识符，用来唯一的标识一个资源
URL：统一资源定位器，它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何locate这个资源

### SYN泛洪攻击

大量恶意请求发起三次握手中的SYN数据包，服务器收到后返回ACK并预留端口等待连接，而恶意请求往往给的是个虚假IP，ACK请求回复等于是无效的，因此大量恶意请求就会造成端口都被占用，正真的请求无法得到连接

解决方法：

- 增加积压队列
- 收回最早的等待客户端ACK的连接
- 收回等待客户端ACK的连接，但放入本地缓存中，如果这个请求ACK真的到达时就再恢复这个连接

## HTTPS

HTTP使用明文传输，内容会被窃听，并且无法校验对方身份，因此可能遭遇伪装

HTTPS其实是HTTP over SSL/TLS，即在应用层HTTP和传输层TCP中加了个安全层SSL/TLS，SSL(Secure Sockets Layer)叫作安全套接层，SSL广泛使用后被标准化，改名为TSL(Transport Layer Security)叫作传输层安全协议

非对称加密 + 对称加密 + CA证书

所谓CA证书是包含了服务商(网站)的公钥，组织信息，域名信息等，然后对这些信息进行一个数字签名(hash)，最后再将签名用CA服务商私钥加密，传到客户端这，客户端用系统内置的CA服务商的公钥解密后得到数字签名，对明文信息进行hash后和解密出的内容做对比，相符就代表正确

1. C -> S 支持的SSL版本，支持的加密算法，随机数1
2. S -> C 确认SSL版本，确认加密算法，随机数2，CA证书
3. C 校验 CA证书(本质是CA服务商的私钥加密了的S端的共钥) 此时C端就确认了S端的公钥
4. C -> S 随机数3(需要用S端的公钥进行加密) hash(第一步，第二步中的数据)
5. S 也计算hash(1，2步中的数据)，判断是否和C端发来的一致，并将随机数1，2，3通过两端间确认的算法生成对称加密用的密钥
6. S -> C hash(1，2，4步中的数据)
7. C 也计算hash(1，2，4步中的数据)判断是否和S端发来一致，并将随机数1，2，3通过两端间确认的算法生成对称加密用的密钥
8. 至此C和S间就都生成了接下来对称加密用的密钥了，就能进行加密传输了

为什么最后通信选择的是对称加密，因为对称加密性能比非对称加密好

## FTP

FTP(File Transfer Protocol)叫作文件传输协议，处在TCP之上的应用层协议

TCP主要有两个端口：
- 21：控制连接，主要用于FTP协议控制信号的传送
- 20：数据连接，主要用于实现应用数据传送

### FTP建立连接方式

主动连接：

客户端首先向服务端21端口发起连接，并随机开启一个临时端口，通过PORT命令将临时端口告知服务端，接着服务端20端口会和客户端的临时端口发起连接来传送数据

在建立数据连接过程中是由服务端发起的，因此叫作主动连接

被动连接：

客户端首先向服务端21端口发起连接，并发送PASV命令告知服务端进入被动状态，服务端会选择个临时端口告知客户端，接着客户端会自己和这个临时端口发起连接，完成数据传输

在建立数据连接过程中是由客户端发起的，因此叫作被动连接

## P2P

P2P(peer-to-peer)，资源不再集中存储在某些设备上，而是分散的存储在多台设备上，这些设备就能理解为peer

### 种子文件(.torrent)

种子文件用来描述你想下载的文件在哪些peer上，其中.torrent文件分为两部分：announce(tracker URL)和文件信息，文件信息中包括了该种子中有哪些文件，文件目录结构，文件被分为段的信息，每个段的哈希值

下载时，BT客户端首先解析.torrent文件，得到tracker地址，连接到tracker服务器后会返回其他peer的ip，然后客户端再和每个peer交换自己有的块和对方有的块，然后客户端每交换到一个块后就会和.torrent中的哈希值做比较已确定下载内容的准确性

整个交换块(即下载数据)的过程中是无需tracker服务器介入的，只有当客户端刚加入网络时才需要tracker服务器来告知其他peer，但是存在一个问题，即每个客户端加入都强依赖于tracker服务器，因此一旦tracker挂了，整个服务就无法运行了

### 去中心化网络(DHT)

DHT(Distributed Hash Table)实现了去中心化网络，每个加入DHT网络的人都要负责存储网络中的资源信息和互相之间的联系信息，相当于所有人一起构成了庞大的分布式存储数据库

Kademlia协议是一个著名的DHT协议，接下来就主要介绍Kademlia协议

任何一个客户端启动后都有两个角色，一个是peer，监听一个TCP端口来上传和下载文件，另一个是DHT node，监听一个UDP的端口来表示这个peer加入到了DHT网络中

每个DHT node上有一个ID，是随机的160位，而文件的哈希也是哈希为了160位。每个DHT node无需保存网络中的所有信息，但必须知道与其的ID相同的文件(文件会哈希成160位)在哪能下载，即使其本身没有保存这个文件。当然整个网络中很难找到文件哈希值和DHT node ID完全相同的一对，因此还要求与这个文件哈希值接近的DHT node也需要知道该文件的下载地址，这里接近的意思就是文件的哈希值和DHT node的ID不同的位数，不同的位数越少就表示越接近(而不是物理上的接近)。

当一个新的DHT node上线时，首先从.torrent文件中获取出node list(不再是tracker URL)，接着尝试和node list中的DHT node进行连接，只要能连接上任意一个就代表成功加入了该DHT网络，接着计算自己想要下载的文件的哈希值，找到该哈希值所对应的DHT node，但这个node很可能自己是不知道在哪的，因此就要通过已知的node来找到所需的node的地址(所有node就像个社交关系网，而有个理论就是关系网中任意两个人之间的距离是不超过六度的，因此是一定能找到node的)，当找到哈希值的DHT node后就知道具体到哪能下载到对应的文件，接着找到文件所在的node连接进行下载。当下载完后，这个新DHT node也就持有了这个文件，接着就可以告诉这个文件哈希值对应的node(不止相同，还有接近的)，即这个新node也可以负责这个文件的下载了，此时一切都分布式了

DHT网络中，ID接近的距离是通过两个ID计算XOR得出的，即高位不同的表示越一些，低位不同表示近一些，当只有最后一位不同时，距离为1，归为k-bucket 1，节点数为2^1，当最后两位不同时，距离为2，归为k-bucket 2，节点数为2^2，以此类推，距离越远，这一层中node也越多

DHT中查找node时，比如目标node的ID和自身距离为5位，首先会去k-bucket 5中查找(k-bucket 5中可能的节点数为2^5，往往这2^5不会全存，而是每一层都只会存配置参数的k个)，如果没能找到，那就从k-bucket 5中任意挑一个node，到它的k-bucket 4继续查找，这样每次搜索的范围都能折半，最坏情况找到k-bucket 1就一定能找到

Kademlia算法中，每个节点只有4个指令：
- PING：测试一个node是否在线
- STORE：要求一个node存储一份数据
- FIND_NODE：根据node ID查找该node
- FIND_VALUE：根据文件计算出的哈希值查找知道该文件信息的node

## DNS

DNS(Domain Name System)称作域名解析系统，负责将域名解析为ip地址

DNS监听53端口上TCP和UDP的数据包，虽然绝大部分走的是UDP，但是当数据包长度过长时，会选择使用TCP来传输，当然只有少部分DNS服务实现了TCP传输

### DNS请求过程

1. 首先在本地DNS缓存中查找`/etc/host`，如果本地缓存中有就直接返回
2. 请求本地DNS服务器，如果本地DNS服务器上有缓存，直接返回，如果通过DHCP方式会自动配置本地DNS服务器
3. 如果本地DNS服务器也没有，就会请求根DNS服务器，全球共13台(`www.google.com.`所有域名最后都有一个`.`，即代表着根域名，只是在显示时往往不显示)
   - 递归：上级DNS服务器自行请求下一级DNS服务器，最后拿到域名对应的ip后返回给本地DNS服务器
   - 迭代：上级DNS服务器直接返回下一级DNS服务器ip，由本地DNS服务器自行请求下一级DNS服务器，直到请求的DNS服务器返回了该域名的ip

### DNS记录类型

- A(Address)：指定域名对应的ip地址
- NS(Name Server)：指定域名的下一级由哪个DNS服务器来解析，NS只允许配置域名，不允许配置ip
- CNAME(Canonical Name)：为域名设置别名，从而使得多个域名映射到同一个域名上。当一个域名设置了CNAME后就不允许设置其他记录了

### DNS的负载均衡

负载均衡：
- DNS服务器将域名解析为多个ip地址(需要配置)，接着客户端在多个ip间循环请求来实现简单的负载均衡
- DNS服务器上通过CNAME配置的方式返回一个域名，接着本地DNS服务器请求这个域名，最终会请求到GSLB(全局负载均衡器)上，在GSLB上可以通过策略来实现负载均衡返回不同的ip，GSLB也可以再返回配置的CNAME，本地DNS服务器接着请求返回的域名，直到最后拿到ip地址
注：负载均衡主要依据请求来自的运营商和请求用户的地理位置

虽然实现了负载均衡，但也存在着如下的问题：
- 域名缓存：因为本地DNS缓存的原因导致无法实时更新到最新的DNS上的数据
- 域名转发：有些服务商会将DNS请求转发给别的服务来实现DNS请求，负载均衡的结果就变成针对别的服务了
- 出口NAT：由于NAT做了地址转化，会导致无法判断请求确切的地址来源
总结：DNS在请求过程中存在大量可能导致DNS服务器无法确切直到请求的来源，因此无法给予有效的负载均衡

为了解决以上问题，就有了HTTPDNS，HTTPDNS不走传统的DNS解析，而是自己搭建基于HTTP协议的DNS服务器集群，分布在多个地点和多个运营商。当客户端需要DNS解析的时候，调用客户端中的SDK直接通过HTTP协议进行请求这个服务器集群(这个请求中会带上确切的自身ip地址，所在运营商等信息)，得到就近的ip地址。此外客户端可以自行配置DNS缓存过期时间，更新时间等配置

HTTPDNS解析中当缓存过期后支持同步更新和异步更新两种方式：
- 同步更新：当发现某个DNS缓存过期后立刻调用HTTPSDNS，实时性比较好，但是当多个缓存同时过期后就需要HTTPDNS请求多次
- 异步更新：将多个缓存过期的请求合并成一个HTTPDNS请求，只用请求一次，但无法保证实时性

## CDN

CDN(Content Delivery Network)称作内容分发网络，下图展示的是CDN的分发系统的架构，客户端寻找边缘节点进行访问，当边缘节点上资源不存在时，会向上一层层请求资源，直到追溯到源服务器(中心节点)将资源拉到本地

![CDN的分发系统的架构](./pics/cdn.jpg)

当配置CDN后，DNS服务器上的域名会配置相应的CNAME，本地DNS请求后会返回对应的CNAME，接着本地DNS服务器会请求返回的域名，这会访问到CDN自己的DNS服务器，在这个DNS服务器上还是会返回CNAME，接着本地DNS通过这个CNAME请求最终访问到CDN网络的全局负载均衡器上

在CDN网络的全局负载均衡器上，通过所属运营商，请求的资源等信息分析后返回最近的边缘节点的ip，客户端访问这个边缘节点来下载资源

- 对于静态页面这类资源，采用拉取的内容分发方式，即发现未命中再去上一级拉取
- 对于流媒体这类资源，采用主动推送的内容分发方式，即上一级主动将热点资源推送给下一级。此外针对流媒体，CDN还会进行预处理，比如将视频预先分为不同清晰度，不同码流来适应不同用户请求

此外，为了防止CDN上资源被盗走，除了简单的HTTP头的refer字段判断外，还有通过时间戳防盗链来实现身份认证的

对于动态数据，CDN有两种模式：
- 边缘计算模式：将数据的逻辑计算和存储都放在边缘节点，即数据在边缘节点动态生成
- 路径优化模式：数据在源服务器(中心节点)上计算动态生成，但数据下发通过CDN网络来找到离用户最近的边缘节点

## VPN

VPN(Virtual Private Network)称作虚拟专用网，就是利用开放的公共网络，建立数据传输通道

![SSL VPN和IPSec VPN比较](./pics/vpn.png)

VPN有很多实现，比如PPTP，L2TP，OPEN VPN，其中较主流的点到点的VPN：IPSec VPN和远程拨号VPN：SSL VPN

IPSec是一组网络安全协议，主要通过加密，验证的方式来提供安全的服务，IPSec VPN将整个网络层数据进行加密后传输

SSL VPN通过与虚拟网卡验证后来获取一张属于自己的虚拟网卡，接着加密后的请求都通过这张虚拟网卡传输

总结：IPSec VPN配置复杂，且需要对整个网络层数据进行加密，SSL VPN更简单灵活

## GFW

GFW(Great Firewall)主要封锁技术：

DNS域名污染：DNS监听53端口上TCP和UDP流量
- UDP：因为UDP是无连接不可靠的，因此GFW在正确DNS数据包返回前插入污染包，使得客户端得到被污染的解析结果，也就是错误的ip地址
- TCP：当三次握手成功后发出DNS请求，但很快会收到RST回应，RST回应本身是用来告知客户端服务器发送故障从而让客户端认为服务器已断开连接不再接受数据包，而GFW就在客户端和DNS服务器之间给双方发送RST请求，从而使得双方都认为对方断开了连接
IP封锁：GFW对于访问被封锁的ip直接截断，此时，唯一的解决办法就是将访问被封锁的请求代理给没被GFW封锁的国外服务器

广义上的VPN指的是翻墙，VPN本身诞生就比墙早且本身的目的也不是用来翻墙，但早期确实可以通过VPN来翻墙，但是VPN协议本身的握手协议特征太过明显，因而很容易被GFW察觉而截断，但VPN也渐渐成了翻墙的代名词

翻墙技术：
- HTTP/HTTPS代理：HTTP代理是明文传输，容易被截断，HTTPS代理虽然包加密了，但部署复杂了，并且HTTP和HTTPS代理都只能代理HTTP协议
  - HTTP：客户端与代理服务器连接，代理服务器将客户端的请求包直接转发给目标地址
  - HTTPS：因为HTTPS是加密的，因此代理服务器无法直到转发到的目标地址，因此客户端需要先发起connect请求要求代理服务器与目标地址建立TCP连接，然后通过隧道的方式将请求包发给代理服务器，代理服务器再直接转发给目标地址
- Socks5：位于传输层和应用层之间的协议，Socks代理只是简单的传递数据包，而不在于应用的协议(如HTTP，FTP等)，其是明文传输的。客户端首先和Socks代理服务器(VPS)进行身份认证，接着客户端将数据包发送给代理服务器来转发给目标地址
- ShadowSocks：加密的Socks5。首先在本地通过Socks5协议与sslocal(本地)连接，接着sslocal(本地)将数据包加密后发送给ssserver(VPS)来转发给目标地址
- ShadowSocksR：混淆增强，比如HTTP和HTTPS混淆，将流量伪装成HTTP/HTTPS的流量，但事实上伪装的HTTP是假的，只有在代理服务器上真正启动个HTTP服务，否则GFW一请求代理服务器就会发现问题
- VMess：V2Ray定义的加密协议。VMess是一个无状态协议，即客户端和服务端无需握手即可直接传输数据。VMess的客户端发起一次请求，服务器会验证并且判断该请求是否来自一个合法的客户端，如果合法则会转发该请求，并把获取的响应返回给客户端

![SOCKS5](./pics/socks5.png)

![shadowsocks](./pics/shadowsocks.png)

上面两张图分别表示了Socks5的结构和ShadowSocks的结构

V2Ray和ShadowSocks区别：
- ShadowSocks是代理工具，提供了图形化界面，而V2Ray是个内核，第三方图形化界面通过调用V2Ray内核api
- 都不支持PAC(代理自动配置)，ShadowSocks通过ACL分流，V2Ray则使用自实现的路由功能
- VMess加密方式由客户端指定，服务器自适应，而ShadowSocks需要配置好加密方法
- VMess使用id(UUID)来代表身份，也就是ShadowSocks的密码的作用
- ShadowSocks直接支持UDP代理，而VMess将UDP转为TCP后进行传输代理 





